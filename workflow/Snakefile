fastq_dir = "/mnt/c/Users/Anthony/Documents/breast_cancer/data/" #ordi
# Version 0.2.0 Projet detection variants / nv transcrits du cancer du seins Projet Dre. Brunet
# >>> Ajout  : procedures de manipulation ARNseq data avec les rules
# >>> À Ajouter : Va falloir automatiser les rentrées de données et la manipulations des fichiers /nom etc. 
# Chaque rule est a corriger / rule all a ajouter et rule wildcards 
# FastQc -> Controle qualité sur les datas
# Trim_Galore -> Trimming des FastQc 
# FastQc -> Vérification que le trimming s'est bien déroulé
# Star -> alignement sur génome de reference  *** 
#merge bam samtool/ module java
###USAGE example(explication/détails des outils): 
#18/09  pipeline fourni la fiche de controle qualité.html mais aussi le zip détaillé ; TRIM-GALORE DONNE UN FICHIER .GZ +TEXT EXPLICATIF, 
# puis un autre controle qualité pour vérifier si trim-galore n'a pas trop tout détruit

#A voir comment faire 
#####
#
#
#
#####
import os
from pathlib import Path
#import pandas as pd




configfile: "../profile_local/config.yaml"
configfile: "../config/config.json"

#include Star et suite
include: "rules/download_genome.smk"  
#include: "rules/star.smk"
#include "rules/analysis.smk"

# test de paths
fastq_dir = "/mnt/c/Users/Antho/Documents/breast_cancer/data/" # sur portable
fastq_dir = "/mnt/c/Users/Anthony/Documents/breast_cancer/data/" #ordi

files = [
    "171992_SIMG0590_T_totalRNA_sarcoma_43378_S9_L001_R1_001.220405.A00516.AHVHTNDSX2.fastq",
    "171992_SIMG0590_T_totalRNA_sarcoma_43378_S9_L002_R2_001.220405.A00516.AHVHTNDSX2.fastq.gz", # portable reconnait .gz mais pas sur pc
]

##################Région inutile##########################
for file in files:
    path = os.path.join(fastq_dir, file)
    print(f"Checking: {path} -> {os.path.exists(path)}")


# Chemins des outils/fichiers (mais servent a rien)
TRIM_GALORE = "trim_galore"
STAR = "STAR"
KALLISTO = "kallisto"
FREEBAYES = "freebayes"
OPENVAR = "OpenVar"



id_list = [
    "171992_SIMG0590_T_totalRNA_sarcoma_43378_S9_L002"  # a grande quantité, un traitement de lignes de fcicher fera cela

]

print(f"Current working directory: {os.getcwd()}")
# Chemin relatif vers le fichier
path = os.path.join("envs", "fastqc.yml")
print(f"Path to check: {path}")
print(f"File exists: {os.path.exists(path)}")
path = "envs/fastqc.yml"
print(f"Checking: {path} -> {os.path.exists(path)}")

######################Région inutile fini######################
rule all:
    input:
        expand("data/qc/{id}_R1_001.220405.A00516.AHVHTNDSX2_fastqc.html", id=id_list),
        expand("data/qc/{id}_R2_001.220405.A00516.AHVHTNDSX2_fastqc.html", id=id_list),
        expand("data/trim_galore/{id}_R1_001.220405.A00516.AHVHTNDSX2_val_2.fq.gz", id=id_list),
        expand("data/trim_galore/{id}_R2_001.220405.A00516.AHVHTNDSX2_val_2.fq.gz", id=id_list),
        expand("data/qc_trim_galore/{id}_1_fastqc.html", id=id_list),
        expand("data/qc_trim_galore/{id}_2_fastqc.html", id=id_list),
        #expand("data/aligned/{id}.bam", id=id_list),   #freebayes
        #expand("data/quantification/{id}.tsv", id=id_list),
        #expand("data/variants/{id}_annotated.vcf", id=id_list)

rule download_genome:
    input:
        gff3 = 'data/references/gff3/homo_sapiens.gff3',
        genome = 'data/references/genome_fa/homo_sapiens_genome.fa',


rule fastqc:
    """Assess the FASTQ quality using FastQC BEFORE TRIMMING"""
    input:
        fq1 = "/mnt/c/Users/Anthony/Documents/breast_cancer/data/{id}_R1_001.220405.A00516.AHVHTNDSX2.fastq.gz",
        fq2 = "/mnt/c/Users/Anthony/Documents/breast_cancer/data/{id}_R2_001.220405.A00516.AHVHTNDSX2.fastq.gz"
    output:
        qc_fq1_out = "data/qc/{id}_R1_001.220405.A00516.AHVHTNDSX2_fastqc.html",
        qc_fq2_out = "data/qc/{id}_R2_001.220405.A00516.AHVHTNDSX2_fastqc.html"
    params:
        out_dir = "data/qc"
    log:
        "logs/fastqc_{id}.log"
    threads: 8
    conda:
        "envs/fastqc.yml" 
    shell:
        "mkdir -p {params.out_dir} && "
        "fastqc --outdir {params.out_dir} --format fastq --threads {threads} {input.fq1} {input.fq2} &> {log}"

# Règle pour le trimming avec trim_galore
rule trim_reads:
    input:
        fq1 = "/mnt/c/Users/Anthony/Documents/breast_cancer/data/{id}_R1_001.220405.A00516.AHVHTNDSX2.fastq.gz",
        fq2 = "/mnt/c/Users/Anthony/Documents/breast_cancer/data/{id}_R2_001.220405.A00516.AHVHTNDSX2.fastq.gz"
    output:
        gal_trim1 = "data/trim_galore/{id}_R1_001.220405.A00516.AHVHTNDSX2_val_2.fq.gz",  # fichier validé pour R1
        gal_trim2 = "data/trim_galore/{id}_R2_001.220405.A00516.AHVHTNDSX2_val_2.fq.gz"  # fichier validé pour R2
#        unpaired1 = "data/trim_galore/{id}_1_unpaired.fq.gz",  # fichier non apparié pour R1
#        unpaired2 = "data/trim_galore/{id}_2_unpaired.fq.gz"   # fichier non apparié pour R2
    threads:
        8
    conda:
        "envs/trim_galore.yml"
    log:
        "logs/trim_{id}.log"
    shell:
        """
        trim_galore --paired {input.fq1} {input.fq2} \
        --output_dir data/trim_galore --gzip \
        &> {log}
        """


rule qc_fastq:
    """ Assess the FASTQ quality using FastQC AFTER TRIMMING"""
    input:
        trimm_fq1 = rules.trim_reads.output.gal_trim1,
        trimm_fq2 = rules.trim_reads.output.gal_trim2,
#        trimm_unpaired_fq1 = rules.trim_reads.output.unpaired1,
#        trimm_unpaired_fq2 = rules.trim_reads.output.unpaired2
    output:
        qc_trimm_fq1_out = "data/qc_trim_galore/{id}_1_fastqc.html",
        qc_trimm_fq2_out = "data/qc_trim_galore/{id}_2_fastqc.html"
    params:
        out_dir = "data/qc_trim_galore"
    log:
        "logs/qc_trim_galore/{id}.log"
    threads:
        8
    conda:
        "envs/fastqc.yml"
    shell:
        "fastqc "
        "--outdir {params.out_dir} "
        "--format fastq "
        "--threads {threads} "
        "{input.trimm_fq1} {input.trimm_fq2} "
#        "{input.trimm_unpaired_fq1} {input.trimm_unpaired_fq2} "
        "&> {log}"

#### a corriger et a tester si ca fonctionne 
rule star_index:
    """ Generates the genome index for STAR """
    input:
        fasta = rules.download_human_genome.output.genome,
        gtf = config['download']['human_gtf']        #GRCh38.p14 reference
    output:
        chrNameLength = config['path']['chrNameLength']
    params:
        dir = config['path']['star_index']
    log:
        "logs/STAR/index.log"
    conda:
        "../envs/star.yml"
    threads:
        8
    shell:
        "mkdir -p {params.dir} && "
        "STAR --runThreadN {threads} "
        "--runMode genomeGenerate "
        "--genomeDir {params.dir} "
        "--genomeFastaFiles {input.fasta} "
        "--sjdbGTFfile {input.gtf} "
        "--sjdbOverhang 99"
        "&> {log}"


rule star_alignreads:
    """ Generates a bam file using STAR """
    input:
        idx = rules.star_index.output,
        fq1 = rules.trim_reads.output.gal_trim1,
        fq2 = rules.trim_reads.output.gal_trim2
    output:
        bam = "results/STAR/{id}/Aligned.sortedByCoord.out.bam",
        bam_logs = "results/STAR/{id}/Log.final.out"
    params:
        index = config['path']['star_index'],
        output_dir = "results/STAR/{id}/"
    log:
        "logs/STAR/{id}.log"
    threads:
        8
    conda:
        "../envs/star.yml"
    shell:
        "STAR --runMode alignReads "
        "--genomeDir {params.index} "
        "--readFilesIn {input.fq1} {input.fq2}  "
        "--runThreadN {threads} "
        "--readFilesCommand zcat "
        "--outReadsUnmapped Fastx "
        "--outFilterType BySJout "
        "--outStd Log "
        "--outSAMunmapped None "
        "--outSAMtype BAM SortedByCoordinate "
        "--outFileNamePrefix {params.output_dir} "
        "--outFilterScoreMinOverLread 0.3 "
        "--outFilterMatchNminOverLread 0.3 "
        "--outFilterMultimapNmax 100 "
        "--winAnchorMultimapNmax 100 "
        "--limitBAMsortRAM 15000000000"         #15go RAM
        "--alignEndsProtrude 5 ConcordantPair "
        "&> {log}"


# Règle pour la quantification des transcrits avec Kallisto
rule build_transcriptome:
    input:
        genome = rules.download_human_genome.output.genome,
        gtf = config['download']['human_gtf']   
    output:
        config["path"]["transcriptome"]
    conda:
        "../envs/gffread.yml"
    message:
        "Build a reference transcriptome using gffread."
    log:
        "logs/build_transcriptome/build_transcriptome.log"
    shell:
        "gffread {input.gtf} -g {input.genome} -w {output}"


rule kallisto_index:
    input:
        rules.build_transcriptome.output
    output:
        "data/references/kallisto.idx"
    params:
        8
    conda:
        "../envs/kallisto.yml"
    log:
        "logs/kallisto/index.log"
    message:
        "Builds an index from the FASTA file."
    shell:
        "kallisto index "
        "--index={output} "
        "--kmer-size={params} "
        "{input} "
        "&> {log}"


rule kallisto_quant:
    input:
        idx = rules.kallisto_index.output,
        fq1 = rules.trim_reads.output.gal_trim1,
        fq2 = rules.trim_reads.output.gal_trim2
    output:
        "results/dge/kallisto/{id}/abundance.tsv"
    params:
        bootstrap = "50",
        outdir = "results/dge/kallisto/{id}"
    threads:
        1
    conda:
        "../envs/kallisto.yml"
    log:
        "logs/kallisto/{id}.log"
    message:
        "Perform pseudoalignment and quantify transcript abundance for {wildcards.id}."
    shell:
        "kallisto quant "
        "--bias "
        "--index={input.idx} "
        "--output-dir={params.outdir} "
        "--bootstrap-samples={params.bootstrap} "
        "--threads={threads} "
        "{input.fq1} {input.fq2} "
        "&> {log}"


rule tx2gene:
    input:
        gtf = config['download']['human_gtf']
    output:
        tsv = "data/references/tx2gene.tsv"
    conda:
        "../envs/python.yml"
    message:
        "Convert transcript IDs to gene IDs."
    script:
        "../scripts/tx2gene.py"


rule filter_gtf_pc_genes:
    input:
        gtf = config['download']['human_gtf']
    output:
        pc_gtf = "data/references/gtf/Homo_sapiens.GRCh38.110_snoRNAs_tRNAs.protein_coding.gtf"
    log:
        "logs/kallisto/filter_gtf_pc_genes.log"
    message:
        "Extract protein coding genes from the genome annotation file."
    shell:
        "grep \'protein_coding\' {input} > {output}"


rule merge_kallisto_quant:
    input:
        quant = expand(rules.kallisto_quant.output, id = id_list),
        tx2gene = rules.tx2gene.output.tsv,
        gtf = rules.filter_gtf_pc_genes.output.pc_gtf
    output:
        tpm = "results/dge/kallisto/tpm.tsv"
    conda:
        "../envs/python.yml"
    log:
        "logs/kallisto/merge_kallisto_quant.log"
    message:
        "Merge kallisto quantification results into one dataframe for further analysis."
    script:
        "../scripts/merge_kallisto_quant.py"


# Règle pour l'appel de variants avec FreeBayes
#rule call_variants:
#    input:
#        bam = "data/aligned/{id}.bam"
#    output:
#        vcf = "data/variants/{id}.vcf"
#    params:
#        freebayes = FREEBAYES
#    log:
#        "logs/freebayes_{id}.log"
#    shell:
#        "{params.freebayes} -f {REFERENCE_GENOME} {input.bam} > {output.vcf} 2> {log}"
#
## Règle pour l'annotation des variants avec OpenVar
#rule annotate_variants:
#    input:
#        vcf = "data/variants/{id}.vcf",
#        transcript_db = TRANSCRIPT_DB
#    output:
#        annotated_vcf = "data/variants/{id}_annotated.vcf"
#    params:
#        openvar = OPENVAR
#    log:
#        "logs/openvar_{id}.log"
#    shell:
#        "{params.openvar} -i {input.vcf} -t {input.transcript_db} -o {output.annotated_vcf} &> {log}"
#





###########fastp
#    params:
#        options = ["--qualified_quality_phred 30", "--length_required 20",
#                "--cut_window_size 1", "--cut_mean_quality 30", "--cut_front",
#                "--cut_tail"]
#    log:
#        "logs/fastp/{id}.log"
#    conda:
#        "envs/fastqc.yml"
#    shell:
#        "fastp -i {input.fq1} -I {input.fq2} "
#        "-o {output.fastq1} -O {output.fastq2} "
#        "--unpaired1 {output.unpaired_fastq1} "
#        "--unpaired2 {output.unpaired_fastq2} "
#        "--thread {threads} "
#        "-h {output.html_report} "
#        "-j {output.json_report} "
#        "{params.options} "
#        "&> {log}"
